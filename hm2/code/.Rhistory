yhat = X%*%bhat
sighat = sqrt(sum((y-yhat)^2)/(n-5))
cov.bhat = solve(t(X)%*%X)*sighat^2
z = qnorm(1-0.05)
width = z * sqrt(diag(X%*%cov.bhat%*%t(X)))
lower = yhat - width
upper = yhat + width
png("hw1_fig_p5.png")
plot(x,y,pch=20)
lines(x,yhat)
lines(x,lower,lwd=2,col=2)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
set.seed(15)
N=200
x = sort(rnorm(N))
beta = rnorm(5)
X = cbind(1, poly(x, 4, raw=TRUE))
y = crossprod(X, beta) + 4 * rnorm(N)
View(X)
y = X%*%beta + 4 * rnorm(N)
y = crossprod(X, beta) + 4 * rnorm(N)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
legend("topright",
legend=c("approach 1", "approach 2"),
col=3:4,
lty=1:1,
lwd=c(1, 1))
source('M:/College Documents/2018 winter/stats 315a/hwk/1/q4.R', echo=TRUE)
train.x=as.matrix(read.csv("train.x",header=F))
train.y=as.matrix(read.csv("train.y",header=F))
test.x=as.matrix(read.csv("test.x",header=F))
test.y=as.matrix(read.csv("test.y",header=F))
library(glmnet)
l=glmnet(train.x,factor(train.y),family="multinomial")
e1=sum(as.numeric(predict(l,train.x,s=l$lambda[99],type="class"))!=
train.y)/length(train.y)
e2=sum(as.numeric(predict(l,test.x,s=l$lambda[99],type="class"))!=
test.y)/length(test.y)
print(e1)
print(e2)
library(MASS);
train.3=read.csv(paste(path,"train.3",sep=""),header=F)
library(MASS);
path="http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/zip.digits/"
train.3=read.csv(paste(path,"train.3",sep=""),header=F)
path="https://web.stanford.edu/~hastie/ElemStatLearn/datasets/zip.digits/"
train.3=read.csv(paste(path,"train.3",sep=""),header=F)
train.x=as.matrix(read.csv("train.x",header=F))
train.y=as.matrix(read.csv("train.y",header=F))
test.x=as.matrix(read.csv("test.x",header=F))
test.y=as.matrix(read.csv("test.y",header=F))
library(glmnet)
l=glmnet(train.x,factor(train.y),family="multinomial")
e1=sum(as.numeric(predict(l,train.x,s=l$lambda[99],type="class"))!=
train.y)/length(train.y)
e2=sum(as.numeric(predict(l,test.x,s=l$lambda[99],type="class"))!=
test.y)/length(test.y)
print(e1)
print(e2)
library(glmnet)
train.x=as.matrix(read.csv("train.x",header=F))
train.y=as.matrix(read.csv("train.y",header=F))
test.x=as.matrix(read.csv("test.x",header=F))
test.y=as.matrix(read.csv("test.y",header=F))
setwd("M:\College Documents\2018 winter\stats 315a\hwk\2\code\hm2\code")
setwd("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code
")
setwd("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code")
train.x=as.matrix(read.csv("train.x",header=F))
train.y=as.matrix(read.csv("train.y",header=F))
test.x=as.matrix(read.csv("test.x",header=F))
test.y=as.matrix(read.csv("test.y",header=F))
View(train.3)
View(train.3)
train=as.matrix(train.3)
l=glmnet(train.x,factor(train.y),family="multinomial")
e1=sum(as.numeric(predict(l,train.x,s=l$lambda[99],type="class"))!=
train.y)/length(train.y)
e1=sum(as.numeric(predict(l,train.x,s=l$lambda[99],type="class"))!=train.y)/length(train.y)
e2=sum(as.numeric(predict(l,test.x,s=l$lambda[99],type="class"))!=test.y)/length(test.y)
train.x=t(as.matrix(read.csv("train.x",header=F)))
train.x=t(as.matrix(read.csv("train.x",header=F)))
train.y=as.matrix(read.csv("train.y",header=F))
test.x=as.matrix(read.csv("test.x",header=F))
test.y=as.matrix(read.csv("test.y",header=F))
library(glmnet)
l=glmnet(train.x,factor(train.y),family="multinomial")
e1=sum(as.numeric(predict(l,train.x,s=l$lambda[99],type="class"))!=train.y)/length(train.y)
train.x=as.matrix(read.csv("train.x",header=F))
train.y=as.matrix(read.csv("train.y",header=F))
test.x=as.matrix(read.csv("test.x",header=F))
test.y=as.matrix(read.csv("test.y",header=F))
library(glmnet)
l=glmnet(train.x,factor(train.y),family="multinomial")
e1=sum(as.numeric(predict(l,train.x,s=l$lambda[99],type="class"))!=train.y)/length(train.y)
train.x[0]
train.x[0,:]
train.x[0,;]
train.x[0,:]
train.x[1,]
train.x[0,]
train.x[1,]
train.x=as.matrix(read.csv("train.x",header=F))
train.y=as.matrix(read.csv("train.y",header=F))
test.x=as.matrix(read.csv("test.x",header=F))
test.y=as.matrix(read.csv("test.y",header=F))
library(glmnet)
l=glmnet(train.x,factor(train.y),family="multinomial")
e1=sum(as.numeric(predict(l,train.x[1,],s=l$lambda[99],type="class"))!=train.y)/length(train.y)
e1=sum(as.numeric(predict(l,train[1,],s=l$lambda[99],type="class"))!=train.y)/length(train.y)
library(MASS)
train.3 = read.csv("E:/0-courses/Stats315A/hw/2/train.3", header=F)
train.5 = read.csv("E:/0-courses/Stats315A/hw/2/train.5", header=F)
train.8 = read.csv("E:/0-courses/Stats315A/hw/2/train.8", header=F)
# data processing
xtrain = rbind(as.matrix(train.3), as.matrix(train.5),
as.matrix(train.8))
ytrain = rep(c(3,5,8), c(nrow(train.3), nrow(train.3), nrow(train.3)))
test = as.matrix(read.table("E:/0-courses/Stats315A/hw/2/zip.test"))
ytest = test[,1]
xtest = test[ytest==3 | ytest == 5 | ytest == 8, -1]
ytest = ytest[ytest == 3 | ytest == 5 | ytest == 8]
showDigit <- function(x, ...) {
p = length(x)
d = sqrt(p)
if (d != round(d)) stop("must be perfect square")
x = matrix(as.numeric(x), d,d)
image(x[,d:1], axes=F, ...)
}
# output
pred_errors = matrix(0, nrow=5, ncol=2)
# part a
l = lda(xtrain, ytrain)
pred_errors[1,1] = sum(predict(l)$class != ytrain) / length(ytrain)
pred_errors[1,2] = sum(predict(l, xtest)$class != ytest) / length(ytest)
# part b
xtrain.center <- apply(xtrain, 2, mean)
xxtrain = scale(xtrain, center = xtrain.center, scale = F)
xxtest = scale(xtest, center = xtrain.center, scale = F)
V = svd(xxtrain)$v[,1:64]
pcstrain = xxtrain %*% V
pcstest = xxtest %*% V
l = lda(pcstrain, ytrain)
pred_errors[2,1] = sum(predict(l)$class != ytrain) / length(ytrain)
pred_errors[2,2] = sum(predict(l, pcstest)$class != ytest) / length(ytest)
# part c
V = scd(xxtrain)$v[, 1:32]
pcstrain = xxtrain %*% V
pcstest = xxtest %*% V
l = lda(pcstrain, ytrain)
pred_errors[3,1] = sum(predict(l)$class != ytrain) / length(ytrain)
pred_errors[3,2] = sum(predict(l, pcstest)$class != ytest) / length(ytest)
# part d
filterdigit <- function(x) {
# average each non-overlapping 2x2 block
x = matrix(x, 16,16)
twos = rep(1:2, 8)
x = x[twos == 1,] + x[twos==2,]
x = x[,twos == 1] + x[,twos==2]
as.vector(x)/4
}
xtrain = t(apply(xtrain, 1, filterdigit))
xtest = t(apply(xtest, 1, filterdigit))
l = lda(xtrain, ytrain)
pred_errors[4,1] = sum(predict(l)$class != ytrain) / length(ytrain)
pred_errors[4,2] = sum(predict(l, xtest)$class != ytest) / length(ytest)
# part e
library(glmnet)
l = glmnet(xtrain, factor(ytrain), family = "multinomial")
pred_errors[5,1] = sum(as.numeric(predict(
l, xtrain, s=l$lambda[99], type = "class"))
!= ytrain) / length(ytrain)
pred_errors[5,2] = sum(as.numeric(predict(
l, xtest, s = l$lambda[99], type = "class"))
!= ytest) / length(ytest)
print(pred_errors)
# output prediction scores
# print(round(pred_errors, 4))
# plot of deviance explained vs. test err
alpha.values = c(0, .25, .5, .75, 1)
#
pred.err = list()
dev.explained = list()
for (i in 1:length(alpha.values)) {
l = glmnet(xtrain, factor(ytrain), family = "multinomial",
alpha = alpha.values[i])
dev.explained[[i]] = l$dev.ratio
pred.err[[i]] = as.numeric(apply(
predict(l, xtest, type = "class") != ytest, 2, mean))
}
my.colors = c("gray90", "gray80", "gray70", "gray50", "gray30", "black")
pdf("p6-plot.pdf", width=10, height=6)
plot(dev.explained[[i]], pred.err[[i]], type="l", col=my.colors[1],
lwd=2, xlab="Deviance Ratio", ylab = "Prediction Error")
title("Prediction Error vs. Training Deviance-Explained")
for (i in 2:length(alpha.values)) {
lines(dev.explained[[i]], pred.err[[i]], col=my.colors[i], lwd=2)
}
alpha.legend = character(length(alpha.values))
for (i in 1:length(alpha.values)) {
alpha.legend[i] = paste("Alpha =", alpha.values[i])
}
legend(x = "topright", legend = alpha.legend, lwd = 4, col = my.colors)
dev.off()
library(MASS)
train.3 = read.csv("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/train.3", header=F)
train.5 = read.csv("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/train.5", header=F)
train.8 = read.csv("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/train.8", header=F)
# data processing
xtrain = rbind(as.matrix(train.3), as.matrix(train.5),
as.matrix(train.8))
ytrain = rep(c(3,5,8), c(nrow(train.3), nrow(train.3), nrow(train.3)))
test = as.matrix(read.table("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/zip.test"))
ytest = test[,1]
xtest = test[ytest==3 | ytest == 5 | ytest == 8, -1]
ytest = ytest[ytest == 3 | ytest == 5 | ytest == 8]
showDigit <- function(x, ...) {
p = length(x)
d = sqrt(p)
if (d != round(d)) stop("must be perfect square")
x = matrix(as.numeric(x), d,d)
image(x[,d:1], axes=F, ...)
}
# output
pred_errors = matrix(0, nrow=5, ncol=2)
# part a
l = lda(xtrain, ytrain)
pred_errors[1,1] = sum(predict(l)$class != ytrain) / length(ytrain)
pred_errors[1,2] = sum(predict(l, xtest)$class != ytest) / length(ytest)
# part b
xtrain.center <- apply(xtrain, 2, mean)
xxtrain = scale(xtrain, center = xtrain.center, scale = F)
xxtest = scale(xtest, center = xtrain.center, scale = F)
V = svd(xxtrain)$v[,1:64]
pcstrain = xxtrain %*% V
pcstest = xxtest %*% V
l = lda(pcstrain, ytrain)
pred_errors[2,1] = sum(predict(l)$class != ytrain) / length(ytrain)
pred_errors[2,2] = sum(predict(l, pcstest)$class != ytest) / length(ytest)
# part c
V = scd(xxtrain)$v[, 1:32]
pcstrain = xxtrain %*% V
pcstest = xxtest %*% V
l = lda(pcstrain, ytrain)
pred_errors[3,1] = sum(predict(l)$class != ytrain) / length(ytrain)
pred_errors[3,2] = sum(predict(l, pcstest)$class != ytest) / length(ytest)
# part d
filterdigit <- function(x) {
# average each non-overlapping 2x2 block
x = matrix(x, 16,16)
twos = rep(1:2, 8)
x = x[twos == 1,] + x[twos==2,]
x = x[,twos == 1] + x[,twos==2]
as.vector(x)/4
}
xtrain = t(apply(xtrain, 1, filterdigit))
xtest = t(apply(xtest, 1, filterdigit))
l = lda(xtrain, ytrain)
pred_errors[4,1] = sum(predict(l)$class != ytrain) / length(ytrain)
pred_errors[4,2] = sum(predict(l, xtest)$class != ytest) / length(ytest)
# part e
library(glmnet)
l = glmnet(xtrain, factor(ytrain), family = "multinomial")
pred_errors[5,1] = sum(as.numeric(predict(
l, xtrain, s=l$lambda[99], type = "class"))
!= ytrain) / length(ytrain)
pred_errors[5,2] = sum(as.numeric(predict(
l, xtest, s = l$lambda[99], type = "class"))
!= ytest) / length(ytest)
print(pred_errors)
# output prediction scores
# print(round(pred_errors, 4))
# plot of deviance explained vs. test err
alpha.values = c(0, .25, .5, .75, 1)
#
pred.err = list()
dev.explained = list()
for (i in 1:length(alpha.values)) {
l = glmnet(xtrain, factor(ytrain), family = "multinomial",
alpha = alpha.values[i])
dev.explained[[i]] = l$dev.ratio
pred.err[[i]] = as.numeric(apply(
predict(l, xtest, type = "class") != ytest, 2, mean))
}
my.colors = c("gray90", "gray80", "gray70", "gray50", "gray30", "black")
pdf("p6-plot.pdf", width=10, height=6)
plot(dev.explained[[i]], pred.err[[i]], type="l", col=my.colors[1],
lwd=2, xlab="Deviance Ratio", ylab = "Prediction Error")
title("Prediction Error vs. Training Deviance-Explained")
for (i in 2:length(alpha.values)) {
lines(dev.explained[[i]], pred.err[[i]], col=my.colors[i], lwd=2)
}
alpha.legend = character(length(alpha.values))
for (i in 1:length(alpha.values)) {
alpha.legend[i] = paste("Alpha =", alpha.values[i])
}
legend(x = "topright", legend = alpha.legend, lwd = 4, col = my.colors)
dev.off()
library(MASS)
train.3 = read.csv("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/train.3", header=F)
train.5 = read.csv("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/train.5", header=F)
train.8 = read.csv("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/train.8", header=F)
# data processing
xtrain = rbind(as.matrix(train.3), as.matrix(train.5),
as.matrix(train.8))
ytrain = rep(c(3,5,8), c(nrow(train.3), nrow(train.3), nrow(train.3)))
test = as.matrix(read.table("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/zip.test"))
ytest = test[,1]
xtest = test[ytest==3 | ytest == 5 | ytest == 8, -1]
ytest = ytest[ytest == 3 | ytest == 5 | ytest == 8]
showDigit <- function(x, ...) {
p = length(x)
d = sqrt(p)
if (d != round(d)) stop("must be perfect square")
x = matrix(as.numeric(x), d,d)
image(x[,d:1], axes=F, ...)
}
library(MASS)
train.3 = read.csv("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/train.3", header=F)
train.5 = read.csv("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/train.5", header=F)
train.8 = read.csv("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/train.8", header=F)
# data processing
xtrain = rbind(as.matrix(train.3), as.matrix(train.5),
as.matrix(train.8))
ytrain = rep(c(3,5,8), c(nrow(train.3), nrow(train.3), nrow(train.3)))
test = as.matrix(read.table("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/zip.test"))
ytest = test[,1]
xtest = test[ytest==3 | ytest == 5 | ytest == 8, -1]
ytest = ytest[ytest == 3 | ytest == 5 | ytest == 8]
showDigit <- function(x, ...) {
p = length(x)
d = sqrt(p)
if (d != round(d)) stop("must be perfect square")
x = matrix(as.numeric(x), d,d)
image(x[,d:1], axes=F, ...)
}
# output
pred_errors = matrix(0, nrow=5, ncol=2)
# part a
l = lda(xtrain, ytrain)
pred_errors[1,1] = sum(predict(l)$class != ytrain) / length(ytrain)
pred_errors[1,2] = sum(predict(l, xtest)$class != ytest) / length(ytest)
clear
clean
rm(list=ls())
library(MASS)
train.3 = read.csv("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/train.3", header=F)
train.5 = read.csv("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/train.5", header=F)
train.8 = read.csv("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/train.8", header=F)
# data processing
xtrain = rbind(as.matrix(train.3), as.matrix(train.5),
as.matrix(train.8))
ytrain = rep(c(3,5,8), c(nrow(train.3), nrow(train.3), nrow(train.3)))
test = as.matrix(read.table("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/zip.test"))
ytest = test[,1]
xtest = test[ytest==3 | ytest == 5 | ytest == 8, -1]
ytest = ytest[ytest == 3 | ytest == 5 | ytest == 8]
showDigit <- function(x, ...) {
p = length(x)
d = sqrt(p)
if (d != round(d)) stop("must be perfect square")
x = matrix(as.numeric(x), d,d)
image(x[,d:1], axes=F, ...)
}
# output
pred_errors = matrix(0, nrow=5, ncol=2)
# part a
l = lda(xtrain, ytrain)
pred_errors[1,1] = sum(predict(l)$class != ytrain) / length(ytrain)
pred_errors[1,2] = sum(predict(l, xtest)$class != ytest) / length(ytest)
View(xtrain)
dim(xtrain)
library(MASS)
train.3 = read.csv("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/train.3", header=F)
train.5 = read.csv("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/train.5", header=F)
train.8 = read.csv("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/train.8", header=F)
# data processing
xtrain = rbind(as.matrix(train.3), as.matrix(train.5),
as.matrix(train.8))
ytrain = rep(c(3,5,8), c(nrow(train.3), nrow(train.5), nrow(train.8)))
test = as.matrix(read.table("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/zip.test"))
ytest = test[,1]
xtest = test[ytest==3 | ytest == 5 | ytest == 8, -1]
ytest = ytest[ytest == 3 | ytest == 5 | ytest == 8]
showDigit <- function(x, ...) {
p = length(x)
d = sqrt(p)
if (d != round(d)) stop("must be perfect square")
x = matrix(as.numeric(x), d,d)
image(x[,d:1], axes=F, ...)
}
# output
pred_errors = matrix(0, nrow=5, ncol=2)
# part a
l = lda(xtrain, ytrain)
pred_errors[1,1] = sum(predict(l)$class != ytrain) / length(ytrain)
pred_errors[1,2] = sum(predict(l, xtest)$class != ytest) / length(ytest)
library(MASS)
train.3 = read.csv("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/train.3", header=F)
train.5 = read.csv("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/train.5", header=F)
train.8 = read.csv("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/train.8", header=F)
# data processing
xtrain = rbind(as.matrix(train.3), as.matrix(train.5),
as.matrix(train.8))
ytrain = rep(c(3,5,8), c(nrow(train.3), nrow(train.5), nrow(train.8)))
test = as.matrix(read.table("M:/College Documents/2018 winter/stats 315a/hwk/2/code/hm2/code/q7/zip.test"))
ytest = test[,1]
xtest = test[ytest==3 | ytest == 5 | ytest == 8, -1]
ytest = ytest[ytest == 3 | ytest == 5 | ytest == 8]
showDigit <- function(x, ...) {
p = length(x)
d = sqrt(p)
if (d != round(d)) stop("must be perfect square")
x = matrix(as.numeric(x), d,d)
image(x[,d:1], axes=F, ...)
}
# output
pred_errors = matrix(0, nrow=5, ncol=2)
# part a
l = lda(xtrain, ytrain)
pred_errors[1,1] = sum(predict(l)$class != ytrain) / length(ytrain)
pred_errors[1,2] = sum(predict(l, xtest)$class != ytest) / length(ytest)
# part b
xtrain.center <- apply(xtrain, 2, mean)
xxtrain = scale(xtrain, center = xtrain.center, scale = F)
xxtest = scale(xtest, center = xtrain.center, scale = F)
V = svd(xxtrain)$v[,1:64]
pcstrain = xxtrain %*% V
pcstest = xxtest %*% V
l = lda(pcstrain, ytrain)
pred_errors[2,1] = sum(predict(l)$class != ytrain) / length(ytrain)
pred_errors[2,2] = sum(predict(l, pcstest)$class != ytest) / length(ytest)
# part c
V = scd(xxtrain)$v[, 1:32]
pcstrain = xxtrain %*% V
pcstest = xxtest %*% V
l = lda(pcstrain, ytrain)
pred_errors[3,1] = sum(predict(l)$class != ytrain) / length(ytrain)
pred_errors[3,2] = sum(predict(l, pcstest)$class != ytest) / length(ytest)
# part d
filterdigit <- function(x) {
# average each non-overlapping 2x2 block
x = matrix(x, 16,16)
twos = rep(1:2, 8)
x = x[twos == 1,] + x[twos==2,]
x = x[,twos == 1] + x[,twos==2]
as.vector(x)/4
}
xtrain = t(apply(xtrain, 1, filterdigit))
xtest = t(apply(xtest, 1, filterdigit))
l = lda(xtrain, ytrain)
pred_errors[4,1] = sum(predict(l)$class != ytrain) / length(ytrain)
pred_errors[4,2] = sum(predict(l, xtest)$class != ytest) / length(ytest)
# part e
library(glmnet)
l = glmnet(xtrain, factor(ytrain), family = "multinomial")
pred_errors[5,1] = sum(as.numeric(predict(
l, xtrain, s=l$lambda[99], type = "class"))
!= ytrain) / length(ytrain)
pred_errors[5,2] = sum(as.numeric(predict(
l, xtest, s = l$lambda[99], type = "class"))
!= ytest) / length(ytest)
print(pred_errors)
# output prediction scores
# print(round(pred_errors, 4))
# plot of deviance explained vs. test err
alpha.values = c(0, .25, .5, .75, 1)
#
pred.err = list()
dev.explained = list()
for (i in 1:length(alpha.values)) {
l = glmnet(xtrain, factor(ytrain), family = "multinomial",
alpha = alpha.values[i])
dev.explained[[i]] = l$dev.ratio
pred.err[[i]] = as.numeric(apply(
predict(l, xtest, type = "class") != ytest, 2, mean))
}
my.colors = c("gray90", "gray80", "gray70", "gray50", "gray30", "black")
pdf("p6-plot.pdf", width=10, height=6)
plot(dev.explained[[i]], pred.err[[i]], type="l", col=my.colors[1],
lwd=2, xlab="Deviance Ratio", ylab = "Prediction Error")
title("Prediction Error vs. Training Deviance-Explained")
for (i in 2:length(alpha.values)) {
lines(dev.explained[[i]], pred.err[[i]], col=my.colors[i], lwd=2)
}
alpha.legend = character(length(alpha.values))
for (i in 1:length(alpha.values)) {
alpha.legend[i] = paste("Alpha =", alpha.values[i])
}
legend(x = "topright", legend = alpha.legend, lwd = 4, col = my.colors)
dev.off()
predict(l,xtrain,s=l$lambda[99],type="class")
predict(
l, xtrain, s=l$lambda[99], type = "class")
